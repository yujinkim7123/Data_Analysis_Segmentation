# agents/service_creator.py

import json
from .utils import get_openai_client, get_columns_for_product
from .data_retriever import fetch_product_context
from qdrant_client.http.models import Filter, FieldCondition, MatchValue 
def _get_json_format_prompt(product_type: str | None) -> str:
    # ... (ì´ í•¨ìˆ˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼, ë³€ê²½ ì—†ìŒ) ...
    tip_field = ""
    if not product_type:
        tip_field = ',\n      "tip": "íŒ: íŠ¹ì • LG ì œí’ˆêµ°ì„ ì§€ì •í•˜ë©´ í•´ë‹¹ ì œí’ˆì— ë” ìµœì í™”ëœ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."'

    return f"""
    ```json
    {{
      "service_ideas": [
        {{
          "service_name": "AI ìœ¡ì•„ ìœ„ìƒ ì»¨ì„¤í„´íŠ¸",
          "description": "í˜ë¥´ì†Œë‚˜ì˜ ì•„ì´ ì—°ë ¹ê³¼ ê±´ê°• ìƒíƒœ(ì˜ˆ: ì•„í† í”¼)ì— ë§ì¶°, ì˜ë¥˜, ì¥ë‚œê°, ì‹ê¸° ë“±ì˜ ìµœì  ì‚´ê·  ì£¼ê¸°ì™€ ë°©ë²•ì„ ì•Œë ¤ì£¼ê³  ê°€ì „ì œí’ˆ(ì„¸íƒê¸°, ê±´ì¡°ê¸° ë“±)ì„ ìë™ìœ¼ë¡œ ì œì–´í•´ì£¼ëŠ” êµ¬ë…í˜• ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.",
          "solved_pain_points": [
            "ì‚´ê·  ê¸°ëŠ¥ì˜ ì‹¤ì œ íš¨ê³¼ë¥¼ ëˆˆìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ì—†ì–´ ë¶ˆì•ˆí•˜ë‹¤",
            "ë§¤ë²ˆ ì˜·ì„ ì‚¶ëŠ” ê²ƒì€ ë²ˆê±°ë¡­ê³  ì˜·ê°ì´ ìƒí• ê¹Œ ê±±ì •ëœë‹¤"
          ],
          "service_scalability": "ì´ˆê¸°ì—ëŠ” ThinQ ì•±ì˜ ê¸°ëŠ¥ìœ¼ë¡œ ì œê³µí•˜ê³ , ì¶”í›„ ì˜ìœ ì•„ ê±´ê°• ë°ì´í„°ë¥¼ ì—°ë™í•œ í”„ë¦¬ë¯¸ì—„ ìœ ë£Œ êµ¬ë… ëª¨ë¸ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì¶•ì ëœ ë°ì´í„°ëŠ” ìƒˆë¡œìš´ ì˜ìœ ì•„ ì „ë¬¸ ê°€ì „ ê°œë°œì˜ ê¸°ë°˜ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }}
      ]{tip_field}
    }}
    ```
    """

# [ë¦¬íŒ©í† ë§] ì¤‘ë³µë˜ëŠ” LLM í”„ë¡¬í”„íŠ¸ ìƒì„± ë¡œì§ì„ ê³µí†µ í•¨ìˆ˜ë¡œ ë¶„ë¦¬
def _build_service_creation_prompt(persona: dict, product_type: str | None, device_columns: dict, feature_docs: list, num_ideas: int) -> str:
    """ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ ìƒì„±ì„ ìœ„í•œ LLM í”„ë¡¬í”„íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤."""
    prompt_header = f"""
    ë‹¹ì‹ ì€ LGì „ìì˜ ì‹ ì‚¬ì—… ê¸°íšì„ ì´ê´„í•˜ëŠ” ìµœê³ ì˜ ì„œë¹„ìŠ¤ ì „ëµê°€ì…ë‹ˆë‹¤.
    ê³ ê° ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬, ê¸°ì¡´ì˜ í‹€ì„ ê¹¨ëŠ” í˜ì‹ ì ì´ë©´ì„œë„ ì‹¤í˜„ ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ë¥¼ ë§Œë“œëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    """
    
    persona_data_prompt = f"""
    ### [ë¶„ì„ ëŒ€ìƒ í˜ë¥´ì†Œë‚˜ ì •ë³´]
    - ì´ë¦„: {persona.get('name')} ({persona.get('title')})
    - ì¸êµ¬í†µê³„: {persona.get('demographics')}
    - í•µì‹¬ ë‹ˆì¦ˆ ë° ëª©í‘œ: {persona.get('needs_and_goals')}
    - **í•µì‹¬ ë¶ˆí¸í•¨ (Pain Points): {persona.get('pain_points')}**
    - ë™ê¸°ë¶€ì—¬ ë¬¸êµ¬: "{persona.get('motivating_quote')}"
    """
    
    product_context_prompt = ""
    if product_type:
        product_context_prompt = f"""
    ### [ê¸°ì¡´ ì œí’ˆ ë° ê¸°ëŠ¥ ì •ë³´ (ì œí’ˆêµ°: {product_type})]
    - ì œí’ˆ ìƒì„¸ ë°ì´í„° í•„ë“œ: {json.dumps(device_columns, ensure_ascii=False)}
    - ê´€ë ¨ ê¸°ëŠ¥ ë¬¸ì„œ ìš”ì•½: {json.dumps(feature_docs, ensure_ascii=False)}
    """
    else:
        product_context_prompt = """
    ### [ê¸°ì¡´ ì œí’ˆ ë° ê¸°ëŠ¥ ì •ë³´]
    - (ì§€ì •ëœ ì œí’ˆêµ° ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.)
    """

    instructions_prompt = f"""
    ### [ì§€ì‹œì‚¬í•­]
    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë°˜ë“œì‹œ ë§Œì¡±í•˜ëŠ” **ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ {num_ideas}ê°œ**ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

    1.  **Pain Point í•´ê²°**: ê° ì•„ì´ë””ì–´ëŠ” í˜ë¥´ì†Œë‚˜ì˜ Pain Point ì¤‘ í•˜ë‚˜ ì´ìƒì„ ëª…í™•í•˜ê³  ì§ì ‘ì ìœ¼ë¡œ í•´ê²°í•´ì•¼ í•©ë‹ˆë‹¤.
    2.  **ê³ ê° ê´€ì **: ì„œë¹„ìŠ¤ê°€ ê³ ê°ì—ê²Œ ì–´ë–¤ ê°€ì¹˜ë¥¼ ì£¼ëŠ”ì§€, ê³ ê°ì´ ì–´ë–»ê²Œ ê²½í—˜í•˜ê²Œ ë ì§€ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•´ì£¼ì„¸ìš”.
    3.  **í˜ì‹ ì„±**: ê¸°ì¡´ì— ì—†ë˜ ìƒˆë¡­ê³  ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”. (ë§Œì•½ ê¸°ì¡´ ì œí’ˆ ì •ë³´ê°€ ìˆë‹¤ë©´, í•´ë‹¹ ì œí’ˆì„ 'í™•ì¥'í•˜ê±°ë‚˜ 'ë³´ì™„'í•˜ëŠ” ì„œë¹„ìŠ¤ì— ì§‘ì¤‘í•˜ì„¸ìš”.)
    4.  **ì„œë¹„ìŠ¤ í™•ì¥ì„± (Scalability)**: ì œì•ˆí•˜ëŠ” ì„œë¹„ìŠ¤ê°€ ì¼íšŒì„± ê¸°ëŠ¥ì— ê·¸ì¹˜ì§€ ì•Šê³ , ë¯¸ë˜ì— ì–´ë–»ê²Œ ì„±ì¥í•˜ê³  í™•ì¥ë  ìˆ˜ ìˆëŠ”ì§€ êµ¬ì²´ì ì¸ ë°©ì•ˆì„ ë°˜ë“œì‹œ í¬í•¨í•´ì£¼ì„¸ìš”. (ì˜ˆ: ë‹¤ë¥¸ ì œí’ˆ ì—°ë™, êµ¬ë… ëª¨ë¸ ë°œì „, ë°ì´í„° ê¸°ë°˜ ê°œì¸í™”, í”Œë«í¼í™” ë“±)
    5.  **ê²°ê³¼ í˜•ì‹**: ì•„ë˜ JSON êµ¬ì¡°ë¥¼ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ê²°ê³¼ë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
    {_get_json_format_prompt(product_type)}
    """
    
    return prompt_header + persona_data_prompt + product_context_prompt + instructions_prompt

# [ìˆ˜ì •] ê¸°ì¡´ í•¨ìˆ˜ë¥¼ ë¦¬íŒ©í† ë§ëœ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
def create_service_ideas(workspace: dict, persona_name: str, num_ideas: int = 3):
    """(ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì— ì €ì¥ëœ) ì§€ì •ëœ í˜ë¥´ì†Œë‚˜ì˜ Pain Pointë¥¼ í•´ê²°í•˜ëŠ” ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    print(f"âœ… [Service Creator] Running Service Idea Generation for '{persona_name}'...")
    client = get_openai_client()
    artifacts = workspace.get("artifacts", {})

    all_personas = artifacts.get("personas")
    if not all_personas:
        return {"error": "ì„œë¹„ìŠ¤ë¥¼ ìƒì„±í•˜ë ¤ë©´ ë¨¼ì € 'í˜ë¥´ì†Œë‚˜ ìƒì„±'ì„ í†µí•´ ê³ ê° í˜ë¥´ì†Œë‚˜ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤."}

    selected_persona = next((p for p in all_personas if p.get("name") == persona_name), None)
    if not selected_persona:
        available_names = ", ".join([f"'{p.get('name')}'" for p in all_personas])
        return {"error": f"'{persona_name}' í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ í˜ë¥´ì†Œë‚˜: [{available_names}]"}

    workspace["artifacts"]["selected_persona"] = selected_persona
    print(f"ğŸ“Œ Persona '{persona_name}' has been set as the selected persona.")

    retrieved_data = artifacts.get("retrieved_data", {})
    artifacts = workspace.get("artifacts", {})
    product_type = retrieved_data.get("product_type")
    
    device_columns = {}
    feature_docs = []
    if product_type:
        print(f"ğŸ” ì œí’ˆêµ° '{product_type}'ì— ëŒ€í•œ ê¸°ì¡´ ì •ë³´ í™œìš© ì¤‘...")
        device_columns = get_columns_for_product(product_type)
        workspace["artifacts"]["product_data"] = device_columns
        feature_docs = retrieved_data.get("product_results", []) 
        
    final_prompt = _build_service_creation_prompt(selected_persona, product_type, device_columns, feature_docs, num_ideas)

    try:
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": final_prompt}],
            response_format={"type": "json_object"}
        )
        service_idea_results = json.loads(res.choices[0].message.content)
        workspace["artifacts"]["service_ideas"] = service_idea_results
        return {"service_ideas_result": service_idea_results}
    except Exception as e:
        print(f"âŒ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"error": f"ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"}

# [ì‹ ê·œ ì¶”ê°€] ìˆ˜ë™ ì…ë ¥ì„ ìœ„í•œ ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ í•¨ìˆ˜
def create_service_ideas_from_manual_input(workspace: dict, persona_description: str, product_type: str = None, num_ideas: int = 3):
    """ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•œ í˜ë¥´ì†Œë‚˜ ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    print(f"âœ… [Service Creator] Running Service Idea Generation from manual input...")
    client = get_openai_client()

    parser_prompt = f"""
    ë‹¤ìŒ í…ìŠ¤íŠ¸ëŠ” ì‚¬ìš©ìê°€ ìƒê°í•˜ëŠ” ê³ ê° í˜ë¥´ì†Œë‚˜ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤. ì´ ì„¤ëª…ì—ì„œ 'ì´ë¦„', 'ì œëª©', 'ì¸êµ¬í†µê³„', 'í•µì‹¬ ë‹ˆì¦ˆ ë° ëª©í‘œ', 'í•µì‹¬ ë¶ˆí¸í•¨(Pain Points)', 'ë™ê¸°ë¶€ì—¬ ë¬¸êµ¬'ë¥¼ ì¶”ì¶œí•˜ì—¬ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
    ë§Œì•½ íŠ¹ì • í•„ë“œì— ëŒ€í•œ ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´, ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡ í•˜ê±°ë‚˜ ë¹„ì›Œë‘ì„¸ìš”.
    ---
    [ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸]: {persona_description}
    ---
    [JSON í˜•ì‹]: {{ "name": "ì‚¬ìš©ì (ê°€ëª…)", "title": "í˜ë¥´ì†Œë‚˜ì˜ íŠ¹ì§•ì„ ë‚˜íƒ€ë‚´ëŠ” ì œëª©", "demographics": "ì¶”ì •ë˜ëŠ” ì¸êµ¬í†µê³„ ì •ë³´", "needs_and_goals": ["ë‹ˆì¦ˆ/ëª©í‘œ 1"], "pain_points": ["ë¶ˆí¸í•¨ 1"], "motivating_quote": "í˜ë¥´ì†Œë‚˜ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ì¸ìš©êµ¬" }}
    """
    try:
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": parser_prompt}],
            response_format={"type": "json_object"}
        )
        selected_persona = json.loads(res.choices[0].message.content)
        print(f"ğŸ” íŒŒì‹±ëœ í˜ë¥´ì†Œë‚˜ ì •ë³´: {selected_persona}")

        workspace["artifacts"]["personas"].append(selected_persona)
        workspace["artifacts"]["selected_persona"] = selected_persona
        print(f"ğŸ“Œ Manually described persona has been created and set as the selected persona.")


    except Exception as e:
        return {"error": f"í˜ë¥´ì†Œë‚˜ ì„¤ëª… ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}

    device_columns = {}
    feature_docs = []
    if product_type:
        print(f"ğŸ” ì œí’ˆêµ° '{product_type}'ì— ëŒ€í•œ ì •ë³´ ì‹¤ì‹œê°„ ì¡°íšŒ ì¤‘...")
        device_columns = get_columns_for_product(product_type)
        workspace["artifacts"]["product_data"] = device_columns
        keyword = selected_persona.get("pain_points", [""])[0] or persona_description
        feature_docs = fetch_product_context(keyword, product_type, top_k=20)
        workspace["artifacts"]["product_type"] = product_type
    final_prompt = _build_service_creation_prompt(selected_persona, product_type, device_columns, feature_docs, num_ideas)

    try:
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": final_prompt}],
            response_format={"type": "json_object"}
        )
        service_idea_results = json.loads(res.choices[0].message.content)
        workspace["artifacts"]["service_ideas"] = service_idea_results
        return {"service_ideas_result": service_idea_results}
    except Exception as e:
        print(f"âŒ ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"error": f"ì„œë¹„ìŠ¤ ì•„ì´ë””ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"}