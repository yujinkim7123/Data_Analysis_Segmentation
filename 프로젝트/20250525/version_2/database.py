from qdrant_client import QdrantClient
from qdrant_client.http.models import PointStruct, VectorParams, Distance
from sentence_transformers import SentenceTransformer
import uuid

# Qdrant ì—°ê²°
qdrant = QdrantClient(host="localhost", port=6333)

# ì„ë² ë”© ëª¨ë¸
embed_model = SentenceTransformer("intfloat/e5-large")

# âœ… ì½œë ‰ì…˜ ìƒì„±
def create_collection(collection_name, vector_size=1024):
    if not qdrant.collection_exists(collection_name):
        qdrant.recreate_collection(
            collection_name=collection_name,
            vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)
        )
        print(f"âœ… Created collection: {collection_name}")

# âœ… ë¬¸ì„œ ì—…ë¡œë“œ (ì„ë² ë”©ì— ë©”íƒ€ë°ì´í„° í¬í•¨)
def upload_documents(text_list, collection_name, tags=None, age_groups=None, summaries=None):
    points = []

    for i, text in enumerate(text_list):
        tag = tags[i] if tags else ""
        age = age_groups[i] if age_groups else ""
        summary = summaries[i] if summaries else ""

        # ë©”íƒ€ë°ì´í„°ê¹Œì§€ í¬í•¨í•´ ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ìƒì„±
        text_for_embedding = f"{text}\níƒœê·¸: {tag}\nìš”ì•½: {summary}\nì—°ë ¹ëŒ€: {age}"
        vector = embed_model.encode(text_for_embedding).tolist()

        # Qdrant payloadì—ëŠ” ì›ë³¸ í•„ë“œ ì €ì¥
        payload = {
            "text": text,
            "tag": tag,
            "age_group": age,
            "summary": summary
        }

        points.append(PointStruct(
            id=str(uuid.uuid4()),
            vector=vector,
            payload=payload
        ))

    qdrant.upsert(collection_name=collection_name, points=points)
    print(f"ğŸ“Œ Uploaded {len(points)} documents to '{collection_name}'")

# âœ… ê²€ìƒ‰ í•¨ìˆ˜
def search_documents(query, collection_name, top_k=5):
    # ì‚¬ìš©ìê°€ ë©”íƒ€ë°ì´í„° í¬í•¨ ê²€ìƒ‰ì„ ì›í•œë‹¤ë©´ ì—¬ê¸°ì„œ í™•ì¥ ê°€ëŠ¥
    vector = embed_model.encode(query).tolist()

    hits = qdrant.search(
        collection_name=collection_name,
        query_vector=vector,
        limit=top_k,
        with_payload=True,
        with_vectors=False
    )

    return [
        {
            "text": h.payload.get("text"),
            "tag": h.payload.get("tag"),
            "age_group": h.payload.get("age_group"),
            "summary": h.payload.get("summary"),
            "score": round(h.score, 4)
        }
        for h in hits
    ]

# âœ… í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    # ì˜ˆì‹œ ë°ì´í„°
    web_texts = [
        "ìš”ì¦˜ ì‚¬ëŒë“¤ì€ ë•€ì„ ë§ì´ í˜ë¦¬ëŠ” ì—¬ë¦„ì² ì— ê¸°ëŠ¥ì„± í‹°ì…”ì¸ ë¥¼ ì„ í˜¸í•œë‹¤.",
        "í¡ìŠµì†ê±´ ê¸°ìˆ ì´ ì ìš©ëœ ì˜·ì€ ìš´ë™ í›„ì—ë„ ì¾Œì í•¨ì„ ìœ ì§€í•´ì¤€ë‹¤."
    ]
    web_tags = ["ì—¬ë¦„ì˜ë¥˜", "ìš´ë™ë³µ"]
    web_ages = ["20ëŒ€", "30ëŒ€"]
    web_summaries = ["ì—¬ë¦„ì²  ë•€ ê´€ë¦¬ì— ëŒ€í•œ ìˆ˜ìš”", "ìš´ë™ í›„ ì¾Œì í•¨ì— ëŒ€í•œ ë‹ˆì¦ˆ"]

    # 1. ì»¬ë ‰ì…˜ ìƒì„±
    create_collection("web_data")

    # 2. ë°ì´í„° ì—…ë¡œë“œ
    upload_documents(web_texts, "web_data", web_tags, web_ages, web_summaries)

    # 3. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    query = "ì—¬ë¦„ì— ë¥ì§€ ì•Šê³  ì¾Œì í•œ ì…”ì¸ "
    print(f"\nğŸ” ê²€ìƒ‰: '{query}'\n")
    results = search_documents(query, "web_data")
    for r in results:
        print(f"ë¬¸ì¥   : {r['text']}")
        print(f"íƒœê·¸   : {r['tag']}")
        print(f"ìš”ì•½   : {r['summary']}")
        print(f"ì—°ë ¹ëŒ€ : {r['age_group']}")
        print(f"ìœ ì‚¬ë„ : {r['score']}\n")
