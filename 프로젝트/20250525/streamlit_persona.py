import streamlit as st
from openai import OpenAI
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.http.models import PointStruct, VectorParams, Distance, Filter, FieldCondition, MatchValue
import sys
import uuid

# ì¸ì½”ë”© ì„¤ì • (Windows ëŒ€ì‘)
sys.stdout.reconfigure(encoding='utf-8')

# OpenAI í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key="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")  # ì‹¤ì œ í‚¤ë¡œ ëŒ€

# ëª¨ë¸ ë¡œë”©
embed_model = SentenceTransformer("intfloat/e5-large")
qdrant = QdrantClient(host="localhost", port=6333)

# í‚¤ì›Œë“œ í™•ì¥ í•¨ìˆ˜
def expand_keywords(keyword):
    prompt = f"""
ë‹¤ìŒì€ ê¸°íšìê°€ ì…ë ¥í•œ ì œí’ˆ ê¸°ëŠ¥ í‚¤ì›Œë“œì•¼: "{keyword}"

ì´ í‚¤ì›Œë“œëŠ” ì†Œë¹„ìê°€ ì¼ìƒì—ì„œ ì§ì ‘ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆì–´.
ì˜ˆë¥¼ ë“¤ì–´ "ì‚´ê· "ì´ë¼ëŠ” ê¸°ëŠ¥ í‚¤ì›Œë“œëŠ” ì¼ë°˜ì¸ì´ "ê¹¨ë—í•œ", "ìœ„ìƒì ì¸", "ì„¸ê·  ê±±ì • ì—†ëŠ”" ê°™ì€ ë§ë¡œ í‘œí˜„í•  ìˆ˜ ìˆì§€.

ì•„ë˜ ê¸°ëŠ¥ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ, **ê¸°ëŠ¥ ê·¸ ìì²´ë¥¼ ì§ì ‘ ë§í•˜ì§€ ì•Šë”ë¼ë„**,
ì¼ë°˜ ì†Œë¹„ìê°€ ì‹¤ì œë¡œ ì‚¬ìš©í•  ë²•í•œ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ì´ë‚˜ ì–´íœ˜ 10ê°€ì§€ë¥¼ ì œì•ˆí•´ì¤˜.

í˜•ì‹ì€ ê°„ê²°í•˜ê²Œ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì œì‹œí•´ì¤˜.
    """
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    return [line.strip("-\u2022 ") for line in response.choices[0].message.content.split("\n") if line.strip()]

# Qdrant ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜ (ë¬¸ì¥ + ë©”íƒ€ë°ì´í„° í¬í•¨)
def search_context(keywords, collection, age_filter=None, top_k=3, min_score=0.75):
    results = []
    for kw in keywords:
        vector = embed_model.encode(kw)

        query_filter = None
        if age_filter:
            query_filter = Filter(
                must=[FieldCondition(key="age_group", match=MatchValue(value=age_filter))]
            )

        hits = qdrant.search(
            collection_name=collection,
            query_vector=vector.tolist(),
            limit=top_k,
            with_payload=True,
            with_vectors=False,
            query_filter=query_filter
        )
        for hit in hits:
            if hasattr(hit, "score") and hit.score >= min_score:
                payload = hit.payload
                results.append({
                    "text": payload.get("text"),
                    "tag": payload.get("tag"),
                    "summary": payload.get("summary"),
                    "age_group": payload.get("age_group"),
                    "score": round(hit.score, 4)
                })
    if len(results) == 0:
        return [{"text": "[ë°ì´í„° ë¶€ì¡±] ì˜ë¯¸ ìˆëŠ” ë¬¸ì¥ì´ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}]
    return results

# í˜ë¥´ì†Œë‚˜ ìƒì„± í•¨ìˆ˜
def generate_personas(expanded_keywords, context_web, context_product):
    def extract_texts(contexts):
        return [item['text'] for item in contexts if "text" in item]

    prompt = f"""
ë„ˆëŠ” ì†Œë¹„ì ì¸ì‚¬ì´íŠ¸ ë¶„ì„ê°€ì•¼. ì•„ë˜ ë¬¸ì¥ê³¼ í‚¤ì›Œë“œë¥¼ ì°¸ê³ í•´ì„œ, ìš°ë¦¬ ì œí’ˆì„ ì¸ì‹í•˜ê±°ë‚˜ ì•„ì§ ì¸ì‹í•˜ì§€ ëª»í•œ ê³ ê° ì¤‘ì—ì„œ, ê¸°íšìê°€ ì œì‹œí•œ ê¸°ëŠ¥ í‚¤ì›Œë“œë¥¼ í•„ìš”ë¡œ í•  ìˆ˜ ìˆëŠ” ë§ˆì´í¬ë¡œ í˜ë¥´ì†Œë‚˜ 10ëª…ì„ ë„ì¶œí•´ì¤˜.

ê° í˜ë¥´ì†Œë‚˜ëŠ” ì•„ë˜ ìš”ì†Œë¥¼ í¬í•¨í•´ì•¼ í•´:
1. í˜ë¥´ì†Œë‚˜ ì´ë¦„ ë˜ëŠ” ìœ í˜•
2. í•´ë‹¹ í˜ë¥´ì†Œë‚˜ê°€ ì œí’ˆì„ ì•Œê³  ìˆëŠ”ì§€ ì—¬ë¶€ (ì¸ì‹/ë¯¸ì¸ì‹)
3. ì£¼ìš” ê´€ì‹¬ì‚¬ ë˜ëŠ” ì¼ìƒ ì† ë‹ˆì¦ˆ
4. ì œí’ˆ ê¸°ëŠ¥ í‚¤ì›Œë“œê°€ í•´ë‹¹ í˜ë¥´ì†Œë‚˜ì—ê²Œ ì™œ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨ë˜ëŠ”ì§€ (ìƒí™© ì¤‘ì‹¬ ì„¤ëª…)

---

ğŸ“Œ ì œí’ˆ ê¸°ëŠ¥ í‚¤ì›Œë“œ:
{', '.join(expanded_keywords)}

ğŸ“‚ ì›¹ í¬ë¡¤ë§ ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ ë¬¸ì¥:
{chr(10).join(extract_texts(context_web))}

ğŸ“¦ ì œí’ˆ ê¸°ëŠ¥ ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ ë¬¸ì¥:
{chr(10).join(extract_texts(context_product))}

ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ, ì„œë¡œ ë‹¤ë¥¸ ìœ í˜•ì˜ ë§ˆì´í¬ë¡œ í˜ë¥´ì†Œë‚˜ 10ëª…ì„ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì œì•ˆí•´ì¤˜.
"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.8
    )
    return response.choices[0].message.content, prompt

# Streamlit UI
st.title("ğŸ§  ë§ˆì´í¬ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„± ì±—ë´‡")

if "history" not in st.session_state:
    st.session_state.history = []

# âœ… ë‚˜ì´ í•„í„° ì„ íƒ UI
age_filter = st.selectbox("ğŸ¯ íƒ€ê²Ÿ ì—°ë ¹ëŒ€ë¥¼ ì„ íƒí•˜ì„¸ìš” (í•„í„°ë§)", ["", "10ëŒ€", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€ ì´ìƒ"], index=0)

user_input = st.chat_input("ì œí’ˆ ê¸°ëŠ¥ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” ì˜ˆ: í¡ìŠµì†ê±´ í‹°ì…”ì¸ ")

if user_input:
    with st.spinner("í˜ë¥´ì†Œë‚˜ ìƒì„± ì¤‘..."):
        st.session_state.history.append(("user", user_input))

        # 1. í‚¤ì›Œë“œ í™•ì¥
        expanded = expand_keywords(user_input)

        # 2. ë¬¸ì¥ ê²€ìƒ‰ (ì—°ë ¹ í•„í„° ë°˜ì˜)
        context_web = search_context(expanded, "web_data", age_filter=age_filter)
        context_product = search_context(expanded, "product_feature_data", age_filter=age_filter)

        # 3. ë°ì´í„° ë¶€ì¡± ì²´í¬
        if all("ë°ì´í„° ë¶€ì¡±" in c.get("text", "") for c in (context_web + context_product)):
            st.warning("ğŸ” í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ë¬¸ì¥ì´ ì¶©ë¶„í•˜ì§€ ì•Šì•„ í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # 4. í˜ë¥´ì†Œë‚˜ ìƒì„±
            personas, used_prompt = generate_personas(expanded, context_web, context_product)
            st.session_state.history.append(("bot", personas))

            # í™•ì¥ í‚¤ì›Œë“œ í‘œì‹œ
            with st.expander("ğŸ“Œ í™•ì¥ëœ í‚¤ì›Œë“œ"):
                for kw in expanded:
                    st.markdown(f"- {kw}")

            # ë¬¸ì¥ + ë©”íƒ€ë°ì´í„° ì¶œë ¥
            def display_docs(context_list, title):
                st.markdown(f"#### {title}")
                for doc in context_list:
                    st.markdown(f"""
- **ë¬¸ì¥**: {doc.get('text')}
  - íƒœê·¸: {doc.get('tag')}
  - ìš”ì•½: {doc.get('summary')}
  - ì—°ë ¹ëŒ€: {doc.get('age_group')}
  - ìœ ì‚¬ë„: {doc.get('score')}
                    """)

            with st.expander("ğŸ” Qdrantì—ì„œ ì¶”ì¶œëœ ë¬¸ì„œ ë³´ê¸°"):
                display_docs(context_web, "ğŸŒ ì›¹ ë°ì´í„°")
                display_docs(context_product, "ğŸ—ï¸ ì œí’ˆ ê¸°ëŠ¥ ë¬¸ì„œ")

            # í”„ë¡¬í”„íŠ¸ ë³´ê¸°
            with st.expander("ğŸ§  LLMì—ê²Œ ì „ë‹¬ëœ ì‹¤ì œ Prompt ë³´ê¸°"):
                st.code(used_prompt, language="markdown")

# íˆìŠ¤í† ë¦¬ ì¶œë ¥
for sender, msg in st.session_state.history:
    with st.chat_message(sender):
        st.markdown(msg)
