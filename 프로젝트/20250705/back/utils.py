# agents/utils.py
import torch
from sentence_transformers import SentenceTransformer, models
from qdrant_client import QdrantClient
from openai import OpenAI, AsyncOpenAI # AsyncOpenAI ì„í¬íŠ¸ë„ ì¤‘ìš”í•©ë‹ˆë‹¤!
import os 
from datetime import datetime, date, timedelta
from dateutil.relativedelta import relativedelta
import re
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from qdrant_client.http.models import Filter, FieldCondition, MatchValue 
import redis
import json
import logging
from redis.lock import Lock
from retry import retry
from typing import Any
sentiment_analyzer = None 

# ëª¨ë¸ê³¼ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜
meaning_model = None
topic_model = None
qdrant_client = None
sync_openai_client = None
async_openai_client = None
redis_client = None


MODEL_NAME = "gpt-4o-mini"


#---logging í•˜ê¸° ìœ„í•œ ê³¼ì • setup--------
def setup_logging():
    logging.basicConfig(
        level=logging.WARNING,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler("mcp_server.log")
        ]
    )
    return logging.getLogger(__name__)


#-----redis ì„¸íŒ…--------------------

def get_redis_client():
    global redis_client
    if redis_client is None:
        print("ğŸŒ€ Initializing Redis client...")
        try:
            redis_client = redis.StrictRedis(
                host=os.getenv("REDIS_HOST", "localhost"),
                port=int(os.getenv("REDIS_PORT", 6379)),
                db=int(os.getenv("REDIS_DB", 0)),
                decode_responses=True,
                socket_timeout=5,
                socket_connect_timeout=5
            )
            redis_client.ping()
            print("âœ… Redis client initialized successfully.")
        except Exception as e:
            print(f"âŒ Failed to initialize Redis client: {e}")
            redis_client = None
    return redis_client

@retry(tries=3, delay=1, backoff=2)
def save_workspace_to_redis(session_id: str, workspace: dict):
    r = get_redis_client()
    if r:
        try:
            with Lock(r, f"lock:session:{session_id}", timeout=10):
                serializable_workspace = _convert_datetime_to_str(workspace)
                # TTLì„ ì‚¬ìš©ì í™œë™ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„¤ì • (ì˜ˆ: 24ì‹œê°„)
                r.setex(f"session:{session_id}:workspace", 86400, json.dumps(serializable_workspace, ensure_ascii=False))
                r.expire(f"session:{session_id}:workspace", 86400)  # ìš”ì²­ ì‹œ TTL ê°±ì‹ 
                print(f"ğŸ’¾ Workspace saved for session: {session_id}")
        except Exception as e:
            print(f"âŒ Failed to save workspace to Redis for session {session_id}: {e}")
            logging.error(f"Redis save error: {e}")
            raise
    else:
        logging.error("Redis client not available")
        raise Exception("Redis connection unavailable")

@retry(tries=3, delay=1, backoff=2)
def load_workspace_from_redis(session_id: str) -> dict | None:
    r = get_redis_client()
    if r:
        try:
            with Lock(r, f"lock:session:{session_id}", timeout=10):
                workspace_json = r.get(f"session:{session_id}:workspace")
                if workspace_json:
                    loaded_workspace = json.loads(workspace_json)
                    deserialized_workspace = _convert_str_to_datetime(loaded_workspace)
                    r.expire(f"session:{session_id}:workspace", 86400)  # ë¡œë“œ ì‹œ TTL ê°±ì‹ 
                    print(f"âœ… Workspace loaded for session: {session_id}")
                    return deserialized_workspace
                print(f"â„¹ï¸ No workspace found for session: {session_id}")
                return None
        except Exception as e:
            print(f"âŒ Failed to load workspace from Redis for session {session_id}: {e}")
            logging.error(f"Redis load error: {e}")
            return None
    return None

# âœ¨ ìƒˆë¡œ ì¶”ê°€í•  í•¨ìˆ˜ ì‹œì‘
def _convert_datetime_to_str(obj: Any) -> Any:
    """Recursively converts datetime and tool_calls objects to serializable format."""
    if isinstance(obj, datetime):
        return obj.isoformat()
    if isinstance(obj, date):
        return obj.isoformat()
    if hasattr(obj, '__dict__') and hasattr(obj, 'id') and hasattr(obj, 'function'):  # tool_calls ì²˜ë¦¬
        return {
            'id': obj.id,
            'type': getattr(obj, 'type', 'function'),
            'function': {
                'name': obj.function.name,
                'arguments': obj.function.arguments
            }
        }
    if isinstance(obj, list):
        return [_convert_datetime_to_str(elem) for elem in obj]
    if isinstance(obj, dict):
        return {k: _convert_datetime_to_str(v) for k, v in obj.items()}
    return obj

def _convert_str_to_datetime(obj: Any) -> Any:
    """Recursively converts ISO strings and tool_calls back to original format."""
    if isinstance(obj, str):
        try:
            return datetime.fromisoformat(obj)
        except ValueError:
            try:
                return date.fromisoformat(obj)
            except ValueError:
                pass
    if isinstance(obj, dict) and 'id' in obj and 'function' in obj:
        from openai.types.chat import ChatCompletionMessageToolCall
        return ChatCompletionMessageToolCall(
            id=obj['id'],
            type=obj.get('type', 'function'),
            function=obj['function']
        )
    if isinstance(obj, list):
        return [_convert_str_to_datetime(elem) for elem in obj]
    if isinstance(obj, dict):
        return {k: _convert_str_to_datetime(v) for k, v in obj.items()}
    return obj


def get_sentiment_analyzer():
    """
    [ì‹ ê·œ] ì‚¬ì „ í•™ìŠµëœ í•œêµ­ì–´ ê°ì„± ë¶„ë¥˜ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    Hugging Faceì˜ pipelineì„ ì‚¬ìš©í•˜ì—¬ ì‰½ê²Œ êµ¬í˜„í•©ë‹ˆë‹¤.
    """
    global sentiment_analyzer
    if sentiment_analyzer is None:
        print("ğŸŒ€ Loading pre-trained sentiment analysis model...")
        
        # Define the local path to your model files
        local_model_path = "C:/Users/User/DIC_Project/persona_mcp_server/agents/models/bert-nsmc" 
        
        try:
            # Load the tokenizer from your local path
            tokenizer = AutoTokenizer.from_pretrained(local_model_path)
            model = AutoModelForSequenceClassification.from_pretrained(local_model_path)

            # 2. pipelineì— ë¡œì»¬ ëª¨ë¸ê³¼ tokenizer ì „ë‹¬
            sentiment_analyzer = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

        except Exception as e:
            print(f"âŒ Error loading sentiment analysis model from local path: {e}")
            sentiment_analyzer = None # Ensure it remains None if loading fails
    return sentiment_analyzer

def get_embedding_models():
    """
    ì˜ë¯¸ ê²€ìƒ‰(e5-large) ëª¨ë¸ê³¼ ì£¼ì œ ê²€ìƒ‰(ko-sbert) ëª¨ë¸ì„ ëª¨ë‘ ë¡œë“œí•©ë‹ˆë‹¤.
    ì´ë¯¸ ë¡œë“œë˜ì—ˆë‹¤ë©´ ê¸°ì¡´ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    global meaning_model, topic_model
    if meaning_model is None or topic_model is None:
        print("ğŸŒ€ Loading embedding models (meaning & topic)...")
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # 1. Meaning Model ë¡œë“œ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
        meaning_model = SentenceTransformer(
            modules=[models.Transformer("intfloat/e5-large"), models.Pooling(1024, pooling_mode_mean_tokens=True)],
            device=device
        )
        
        # 2. Topic Model ë¡œë“œ (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
        topic_model = SentenceTransformer("jhgan/ko-sbert-nli", device=device)
        
        print("âœ… All embedding models loaded.")
        
    return meaning_model, topic_model

def get_qdrant_client():
    """Qdrant í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    global qdrant_client
    if qdrant_client is None:
        print("ğŸŒ€ Initializing Qdrant client...")
        qdrant_client = QdrantClient(host="localhost", port=6333)
        print("âœ… Qdrant client initialized.")
    return qdrant_client

def get_openai_client(async_client=False):
    """
    [ê°œì„ ë¨] OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    async_client=True ì´ë©´ ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼, False(ê¸°ë³¸ê°’)ì´ë©´ ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ìµœì´ˆ í˜¸ì¶œ ì‹œ, í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì½ì–´ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    global sync_openai_client, async_openai_client
    
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("'.env' íŒŒì¼ì— OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    if async_client:
        # ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ê°€ í•„ìš”í•œ ê²½ìš°
        if async_openai_client is None:
            print("ğŸŒ€ Initializing Async OpenAI client...")
            async_openai_client = AsyncOpenAI(api_key=api_key)
        return async_openai_client
    else:
        # ë™ê¸° í´ë¼ì´ì–¸íŠ¸ê°€ í•„ìš”í•œ ê²½ìš° (ê¸°ë³¸ê°’)
        if sync_openai_client is None:
            print("ğŸŒ€ Initializing Sync OpenAI client...")
            sync_openai_client = OpenAI(api_key=api_key)
        return sync_openai_client

def parse_natural_date(text: str | None) -> tuple | None:
    """
    [ìµœì¢… ìˆ˜ì •] '1ë…„ê°„', '3ê°œì›”ê°„' ë“±ì˜ í‘œí˜„ë„ ì¸ì‹í•˜ë„ë¡ ì •ê·œí‘œí˜„ì‹ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.
    """
    if not text:
        return None

    today = datetime.now()
    text = text.lower()
    
    match = re.search(r'(?:ìµœê·¼|ì§€ë‚œ)\s*(\d+)\s*(ê°œì›”|ë‹¬|ë…„|ì£¼|ì¼)ê°„?', text)
    if match:
        num, unit = int(match.group(1)), match.group(2)
        end_date = today.date()
        if 'ë…„' in unit:
            start_date = (today - timedelta(days=num*365)).date()
        elif 'ì£¼' in unit:
            start_date = (today - timedelta(days=num*7)).date()
        elif 'ì¼' in unit:
            start_date = (today - timedelta(days=num)).date()
        else: # ê°œì›” ë˜ëŠ” ë‹¬
            start_date = (today - timedelta(days=num*30)).date()
        return start_date, end_date

    # ë‹¤ë¥¸ íŒ¨í„´ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    if 'ì˜¬í•´' in text or 'ì´ë²ˆ ë…„ë„' in text:
        return datetime(today.year, 1, 1).date(), today.date()
    if 'ì‘ë…„' in text:
        last_year = today.year - 1
        return datetime(last_year, 1, 1).date(), datetime(last_year, 12, 31).date()

    if 'ì´ë²ˆ ë‹¬' in text:
        return today.replace(day=1).date(), today.date()
    if 'ì§€ë‚œ ë‹¬' in text:
        first_day_of_current_month = today.replace(day=1)
        last_day_of_last_month = first_day_of_current_month - timedelta(days=1)
        first_day_of_last_month = last_day_of_last_month.replace(day=1)
        return first_day_of_last_month.date(), last_day_of_last_month.date()

    if 'ì–´ì œ' in text:
        yesterday = (today - timedelta(days=1)).date()
        return yesterday, yesterday
    if 'ì˜¤ëŠ˜' in text:
        return today.date(), today.date()
        
    return None