import streamlit as st
from openai import OpenAI
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.http.models import Filter, FieldCondition, MatchValue
import sys

sys.stdout.reconfigure(encoding='utf-8')

client = OpenAI(api_key="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")  # ğŸ” ì‹¤ì œ í‚¤ë¡œ êµì²´
embed_model = SentenceTransformer("intfloat/e5-large")
qdrant = QdrantClient(host="localhost", port=6333)

# ğŸ” í‚¤ì›Œë“œ í™•ì¥
def expand_keywords(keyword):
    prompt = f"""
ë‹¹ì‹ ì€ ì†Œë¹„ì ì–¸ì–´ ë¶„ì„ ì „ë¬¸ê°€ì´ì, ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ê¸°íšìê°€ ì •ì˜í•œ ì œí’ˆ ê¸°ëŠ¥ í‚¤ì›Œë“œì…ë‹ˆë‹¤:
ğŸ”§ "{keyword}"

í•˜ì§€ë§Œ ì†Œë¹„ìëŠ” ì¼ìƒ ëŒ€í™”ì—ì„œ í•´ë‹¹ ê¸°ëŠ¥ì„ ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì˜ˆ: "ì‚´ê· " â†’ "ê¹¨ë—í•œ", "ì„¸ê·  ê±±ì • ì—†ëŠ”" ë“±

ì•„ë˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì†Œë¹„ì í‘œí˜„ 10ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”:

âœ… ê¸°ëŠ¥ì„ ëª°ë¼ë„ ì¼ìƒì—ì„œ ì“°ëŠ” ë§  
âœ… ê°ì •/ìƒí™©/ë‹ˆì¦ˆë¥¼ ë‹´ì€ í‘œí˜„  
âœ… ê´‘ê³  ë¬¸êµ¬ê°€ ì•„ë‹Œ ì§„ì§œ ì‚¬ìš©ì ë§íˆ¬  

ê²°ê³¼ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ:
- ë•€ì´ ë‚˜ë„ ì‹œì›í•œ
- í•˜ë£¨ ì¢…ì¼ ë½€ì†¡í•œ ëŠë‚Œ
    """
    res = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    return [line.strip("-â€¢ ") for line in res.choices[0].message.content.split("\n") if line.strip()]

# ğŸ” Qdrant ë¬¸ì„œ ê²€ìƒ‰
def search_context(keywords, collection, age_filters=None, tag=None, top_k=3, min_score=0.75):
    results = []
    seen = set()
    for kw in keywords:
        vector = embed_model.encode(kw)
        must = []
        if collection == "web_data" and age_filters:
            must.append(FieldCondition(key="age_group", match=MatchValue(value=age_filters[0])))
        if collection == "product_feature_data" and tag:
            must.append(FieldCondition(key="tag", match=MatchValue(value=tag)))
        query_filter = Filter(must=must) if must else None

        hits = qdrant.search(
            collection_name=collection,
            query_vector=vector.tolist(),
            limit=top_k,
            with_payload=True,
            with_vectors=False,
            query_filter=query_filter
        )
        for hit in hits:
            text = hit.payload.get("text")
            if text and text not in seen and hit.score >= min_score:
                seen.add(text)
                results.append({
                    "text": text,
                    "tag": hit.payload.get("tag"),
                    "summary": hit.payload.get("summary"),
                    "age_group": hit.payload.get("age_group"),
                    "score": round(hit.score, 4)
                })
    return results if results else [{"text": "[ë°ì´í„° ë¶€ì¡±] ì˜ë¯¸ ìˆëŠ” ë¬¸ì¥ì´ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}]

# ğŸ¤– í˜ë¥´ì†Œë‚˜ ìƒì„±
def generate_personas(expanded_keywords, context_web, context_product, user_input):
    def extract_texts(contexts): return [i['text'] for i in contexts if "text" in i]
    prompt = f"""
ë‹¹ì‹ ì€ ê³ ê° ì¸ì‚¬ì´íŠ¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ë„ˆëŠ” ì†Œë¹„ì ì¸ì‚¬ì´íŠ¸ ë¶„ì„ê°€ì•¼. ì•„ë˜ ë¬¸ì¥ê³¼ í‚¤ì›Œë“œë¥¼ ì°¸ê³ í•´ì„œ, ìš°ë¦¬ ì œí’ˆì„ ì¸ì‹í•˜ê±°ë‚˜ ì•„ì§ ì¸ì‹í•˜ì§€ ëª»í•œ ê³ ê° ì¤‘ì—ì„œ, ê¸°íšìê°€ ì œì‹œí•œ ê¸°ëŠ¥ í‚¤ì›Œë“œë¥¼ í•„ìš”ë¡œ í•  ìˆ˜ ìˆëŠ” ë§ˆì´í¬ë¡œ í˜ë¥´ì†Œë‚˜ 10ëª…ì„ ë„ì¶œí•´ì¤˜.

ê° í˜ë¥´ì†Œë‚˜ëŠ” ì•„ë˜ í•­ëª©ì„ í¬í•¨í•©ë‹ˆë‹¤:
1. ğŸ§â€â™€ï¸ í˜ë¥´ì†Œë‚˜ ì´ë¦„ ë˜ëŠ” ìœ í˜•
2. ğŸ” ì œí’ˆ ì¸ì‹ ìƒíƒœ (ì¸ì‹/ë¯¸ì¸ì‹)
3. ğŸ§  ì£¼ìš” ê´€ì‹¬ì‚¬ ë˜ëŠ” ìƒí™œ ì† ë‹ˆì¦ˆ
4. âœ… ê¸°ëŠ¥ì´ ì™œ í•„ìš”í•œì§€ (ìƒí™© ì¤‘ì‹¬ ì„¤ëª…)

---

ğŸ“Œ ì œí’ˆ ê¸°ëŠ¥ í‚¤ì›Œë“œ
{user_input}

ğŸ“Œ ê¸°ëŠ¥ í‚¤ì›Œë“œ ë° í™•ì¥:
{', '.join(expanded_keywords)}

ğŸŒ ì›¹ ë¬¸ì„œ ë¬¸ì¥:
{chr(10).join(extract_texts(context_web))}

ğŸ—ï¸ ê¸°ëŠ¥ ë¬¸ì„œ ë¬¸ì¥:
{chr(10).join(extract_texts(context_product))}
---
"""
    res = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.8
    )
    return res.choices[0].message.content, prompt

# âœ… UI
st.set_page_config("ë§ˆì´í¬ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±ê¸°", layout="wide")
st.title("ğŸ§  ë§ˆì´í¬ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±ê¸°")

age_filters = st.multiselect("ğŸ¯ ì›¹ ë¬¸ì„œ ì—°ë ¹ í•„í„°", ["10ëŒ€", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€ ì´ìƒ"])
user_input = st.text_input("ğŸ“ ì œí’ˆ ê¸°ëŠ¥ í‚¤ì›Œë“œ ì…ë ¥", placeholder="ì˜ˆ: í¡ìŠµì†ê±´ í‹°ì…”ì¸ ")

if st.button("ğŸš€ í˜ë¥´ì†Œë‚˜ ìƒì„±í•˜ê¸°") and user_input:
    with st.spinner("ğŸ”„ í™•ì¥ í‚¤ì›Œë“œ ë° ë¬¸ì„œ ê²€ìƒ‰ ì¤‘..."):
        expanded = expand_keywords(user_input)
        context_web = search_context(expanded, "web_data", age_filters=age_filters)
        context_product = search_context([user_input], "product_feature_data", tag=user_input)

        if all("ë°ì´í„° ë¶€ì¡±" in x.get("text", "") for x in (context_web + context_product)):
            st.warning("ğŸ“‰ ê´€ë ¨ ë¬¸ì¥ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            personas, used_prompt = generate_personas(expanded, context_web, context_product, user_input)
            st.success("âœ… í˜ë¥´ì†Œë‚˜ ìƒì„± ì™„ë£Œ")

            st.markdown("### ğŸ“Œ í™•ì¥ëœ í‚¤ì›Œë“œ")
            st.markdown(" ".join([f"`{kw}`" for kw in expanded]))

            with st.expander("ğŸ“‚ Qdrantì—ì„œ ì¶”ì¶œëœ ë¬¸ì„œ"):
                for doc in context_web + context_product:
                    st.markdown(f"""
**ë¬¸ì¥**: {doc.get("text")}  
- íƒœê·¸: {doc.get("tag")}
- ìš”ì•½: {doc.get("summary")}
- ì—°ë ¹ëŒ€: {doc.get("age_group")}
- ìœ ì‚¬ë„: {doc.get("score")}
""")

            st.markdown("### ğŸ¯ ë§ˆì´í¬ë¡œ í˜ë¥´ì†Œë‚˜ ì¹´ë“œ")
            for i, block in enumerate(personas.strip().split("\n\n")):
                st.markdown(f"#### ğŸ§  í˜ë¥´ì†Œë‚˜ {i+1}")
                st.markdown(block)

            with st.expander("ğŸ§  LLMì—ê²Œ ì „ë‹¬ëœ í”„ë¡¬í”„íŠ¸"):
                st.code(used_prompt, language="markdown")
